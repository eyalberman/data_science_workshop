
---
title: "Eyal Berman - Workshop in Data Science"
output: html_notebook
---

```{r}
skip_computation <- FALSE

list.of.packages <-
  c(
  "ggplot2",
  "dplyr",
  "tidyr",
  "randomForest",
  "caret",
  "hydroGOF",
  "ETLUtils",
  "reshape"
  )
  new.packages <-
  list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
  if (length(new.packages)){
    install.packages(new.packages)
  }
  invisible(lapply(list.of.packages, require, character.only = TRUE))
  source('ds_project_functions.R')
  
```


Now, start loading features into the dataset:

Load tables
```{r}
target_data <- read.csv("WorldBank/Millennium_development_goals.csv")
poverty <- read.csv('WorldBank/poverty_and_equity.csv', na.strings = c('..',''))
gender <- read.csv('WorldBank/gender_statistics_female.csv', na.strings = c('..',''))
africa_infra <- read.csv('WorldBank/Africa_Infrastructure.csv', na.strings = c('..',''))
africa_development <- read.csv('WorldBank/africa_development_indicators.csv', na.strings = c('..',''))
health_nutrition <- read.csv('WorldBank/health_and_nutrition.csv', na.strings = c('..',''))
```

Prepare tables for training (transpose + fix values)
```{r}
target_data <- prepare_target_data(target_data)
poverty <- prepare_data_df_to_pivot(poverty)
gender <- prepare_data_df_to_pivot(gender)
africa_infra <- prepare_data_df_to_pivot(africa_infra)
africa_infra$Country.Name <- gsub(" ","",gsub("_[A-Z]+","", gsub("\\d.","", (africa_infra$Country.Name))))
health_nutrition <- prepare_data_df_to_pivot(health_nutrition)
africa_development <- prepare_african_development_df(africa_development)

africa_countries <- africa_development$Country.Name %>% unique()
```


Join the tables into one big dataset, then filter it to include African countries only
```{r}
joined_table <- create_joined_table()
african_joined_table <- joined_table %>% filter(Country.Name.x %in% africa_countries)
```

# Data Preperation #


##Remove trivial fields##
Remove fields that directly relate to life expectency and death.
The list was comprised by running the model and looking at the imporant fields list - then identifying the non-interesting features and removing them
```{r}
ColumnsToRemove <- c("Mortality","Death.rate","Life.expectancy","Lifetime.risk","Survival.to","Population.ages","Number.of.under.five.deaths","Number.of.infant.deaths","Number.of.neonatal.deaths")

ColumnsToRemoveNumbers <- unique (grep(paste(ColumnsToRemove,collapse="|"), 
                        colnames(african_joined_table)))
african_joined_table <- african_joined_table[ ,  -ColumnsToRemoveNumbers]
```

##Remove columns with lots of null values##
```{r}
african_joined_table_orig <- african_joined_table
african_joined_table <- remove_large_null_columns(african_joined_table, 0.3)
```

##Prepare data for model training##
Impute null values, removing rows with no observation data
```{r}
african_joined_table$Country.Code <- as.factor(african_joined_table$Country.Code)
african_joined_table.imputed <- na.roughfix(african_joined_table)

suppressWarnings(african_joined_table.imputed$Mort_Rate_under_5 <-       
  as.numeric(paste(african_joined_table.imputed$Mort_Rate_under_5)))
 # Remove NA rows
african_joined_table.imputed <- african_joined_table.imputed %>% filter(Mort_Rate_under_5 >= 0)
```

## Randomly split the data ##
Split the data into training (80%) and testing (20%) sets
```{r}
smp_size <- floor(0.8 * nrow(african_joined_table.imputed))

set.seed(123)
train_ind <- sample(seq_len(nrow(african_joined_table.imputed)), size = smp_size)
train <- african_joined_table.imputed[train_ind, ]
test <- african_joined_table.imputed[-train_ind, ]
```

## Training the model ##
```{r}
if (skip_computation) {
    rf.model <- readRDS("./final_rf_model.rds")
} else {
  rf.model <-train_model(600,20)
}

# saveRDS(rf.model, "./final_rf_model.rds")
```
## Testing the model ##
The most important features are:
```{r, fig.width = 6}
prediction <- predict(rf.model, test)
compare_df <- data.frame(prediction,test$Mort_Rate_under_5, prediction - test$Mort_Rate_under_5)
varImpPlot(rf.model,type=1)
```
This chart shows the IncNodePurity, which stands for "Increased Node Purity" - 

```{r, fig.width=6}
varImpPlot(rf.model,type=2)
```

##rMSE##
```{r}
rmse_prediction <- rmse(compare_df$prediction, compare_df$test.Mort_Rate_under_5)
mean_mortality_rate <- mean(african_joined_table.imputed$Mort_Rate_under_5)
median_mortality_rate <- median(african_joined_table.imputed$Mort_Rate_under_5)
cat(" rMSE is",round(rmse_prediction,2),"\n","mean_mortality_rate is ",round(mean_mortality_rate,2),"\n",
    "median_mortality_rate is ",round(median_mortality_rate,2))

```
#Fine Tune the Model Parameters#
```{r}
if (skip_computation) {
  cat("This results of this is that the best combination is TODO\n")
} else {
train_predict_and_evaluate_model(test,600,46)
train_predict_and_evaluate_model(test,600,100)
train_predict_and_evaluate_model(test,600,30)
train_predict_and_evaluate_model(test,600,20)
train_predict_and_evaluate_model(test,600,10)
train_predict_and_evaluate_model(test,300,46)
train_predict_and_evaluate_model(test,300,30)
train_predict_and_evaluate_model(test,300,20)
train_predict_and_evaluate_model(test,300,10)
train_predict_and_evaluate_model(test,150,46)
train_predict_and_evaluate_model(test,150,30)
train_predict_and_evaluate_model(test,150,20)
train_predict_and_evaluate_model(test,150,10)
train_predict_and_evaluate_model(test,50,100)
train_predict_and_evaluate_model(test,50,46)
train_predict_and_evaluate_model(test,50,30)
train_predict_and_evaluate_model(test,50,20)
train_predict_and_evaluate_model(test,50,10)
}
```
Test the data for without removing null columns:
```{r}
african_joined_table_orig$Country.Code <- as.factor(african_joined_table_orig$Country.Code)
african_joined_table_orig.imputed <- na.roughfix(african_joined_table_orig)
suppressWarnings(african_joined_table.imputed$Mort_Rate_under_5 <-       
  as.numeric(paste(african_joined_table.imputed$Mort_Rate_under_5)))
 # Remove NA rows
african_joined_table.imputed <- african_joined_table.imputed %>% filter(Mort_Rate_under_5 >= 0)

smp_size <- floor(0.8 * nrow(african_joined_table.imputed))

set.seed(123)
train_ind <- sample(seq_len(nrow(african_joined_table.imputed)), size = smp_size)

train <- african_joined_table.imputed[train_ind, ]
test <- african_joined_table.imputed[-train_ind, ]

if (skip_computation) {
    rf.model <- readRDS("./final_rf_model_with_null.rds")
} else {
  rf.model <-train_model(600,20)
}
rmse_prediction <- rmse(compare_df$prediction, compare_df$test.Mort_Rate_under_5)
mean_mortality_rate <- mean(african_joined_table.imputed$Mort_Rate_under_5)
median_mortality_rate <- median(african_joined_table.imputed$Mort_Rate_under_5)
cat(" rMSE without removing null columns is",round(rmse_prediction,2),"\n","mean_mortality_rate is ",round(mean_mortality_rate,2),"\n",
    "median_mortality_rate is ",round(median_mortality_rate,2))
```
```{r, fig.width=6}
varImpPlot(rf.model,type=1)
```
# As we can see, there's no need to remove the features with high null value percentages, since Random Forest is a very robust machine learning algorithm #

Plotting some data:
```{r,fig.width=5}
 plot_chart("Adolescent.fertility.rate..births.per.1.000.women.ages.15.19.","fertelity rate 15-19",c(1990,2010))
```




```{r,fig.width=5}
plot_chart("Age.dependency.ratio..young","Age dependency ratio",c(2000))

```

*Age dependency ratio, young, is the ratio of younger dependents--people younger than 15--to the working-age population--those ages 15-64. Data are shown as the proportion of dependents per 100 working-age population.
(from the world bank, http://data.worldbank.org/indicator/SP.POP.DPND.YG)

```{r,fig.width=5}
 plot_chart("Immunization..Pol3....of.one.year.old.children.","Polio Immunization rate among children under 1 year old",c(2000))

```

```{r,fig.width=5}
 plot_chart("Telephone.mainlines..per.1.000.people.","Mortality rate among children under 5 vs Telephone lines per 1,000 people",c(1990,2010))
```

```{r,fig.width=5}
 plot_chart("People.practicing.open.defecation..urban....of.urban.population.","open defecation",c(1990))
```

*People practicing open defecation refers to the percentage of the population defecating in the open, such as in fields, forest, bushes, open bodies of water, on beaches, in other open spaces or disposed of with solid waste.
(The World Bank, <http://data.worldbank.org/indicator/SH.STA.ODFC.UR.ZS>)

```{r,fig.width=5}ne
 plot_chart("Newborns.protected.against.tetanus....","Newborns.protected.against.tetanus",c(1990,2010))
```
*Newborns protected against tetanus are the percentage of births by women of child-bearing age who are immunized against tetanus.
(The World Bank, <http://data.worldbank.org/indicator/SH.VAC.TTNS.ZS>)

```{r,fig.width=5}
 plot_chart("School.enrollment..primary..female....gross.","School.enrollment.primary.female",c(1990,2010))
```

```{r,fig.width=5}
 plot_chart("Ratio.of.female.to.male.labor.force.participation.rate......modeled.ILO.estimate.","Ratio of female to male labor force participation rate",c(1990,2010))
```
* Labor force participation rate is the proportion of the population ages 15 and older that is economically active: all people who supply labor for the production of goods and services during a specified period.
(The World Bank, <http://data.worldbank.org/indicator/SL.TLF.CACT.FM.ZS>)


len = length(data$Mort_Rate_under_5)
df <- data.frame(x=c(data$School.enrollment..primary..female....gross.,
                      data$Ratio.of.female.to.male.labor.force.participation.rate......modeled.ILO.estimate.,
                      data$Telephone.mainlines..per.1.000.people.,
                      data$Immunization..Pol3....of.one.year.old.children.,
                      data$People.practicing.open.defecation..urban....of.urban.population.),
                    y=rep(data$Mort_Rate_under_5,5), class=c(rep("y1", len), rep("y2", len), rep("y3",len),rep("y4",len), rep("y5",len)))
ggplot(df, aes(x=x, y=y, color=class)) + geom_point() +     geom_smooth(method="lm",se=FALSE, (aes(color=class)))


df2 < african_joined_table_orig.imputed[,c(4,7,8,9)]

ggplot(df2) +
  geom_jitter(aes(Mort_Rate_under_5,X12th.pillar..Innovation, colour=class),) + 
  geom_smooth(aes(Mort_Rate_under_5,X2nd.pillar..Infrastructure, colour = class), method=lm) +
  facet_wrap(~class, scales="free_x") +
  labs(x = "Percentage cover (%)", y = "Number of individuals (N)")


ggplot(df) + 
  geom_jitter(aes(Mort_Rate_under_5,X12th.pillar..Innovation, colour=class), colour="blue") + geom_smooth(aes(Mort_Rate_under_5,X12th.pillar..Innovation, colour=class), method=lm, se=FALSE) +
  geom_jitter(aes(y2,x), colour="green") + geom_smooth(aes(y2,x), method=lm, se=FALSE) +
  geom_jitter(aes(y3,x), colour="red") + geom_smooth(aes(y3,x), method=lm, se=FALSE) +
  labs(x = "Percentage cover (%)", y = "Number of individuals (N)")


ggplot(mtcars2) +
  geom_jitter(aes(value,mpg, colour=variable),) + geom_smooth(aes(value,mpg, colour=variable), method=lm, se=FALSE) +
  facet_wrap(~variable, scales="free_x") +
  labs(x = "Percentage cover (%)", y = "Number of individuals (N)")


df <- data.frame(x=rep(x,2), y=c(y1, y2), class=c(rep("y1", 5), rep("y2", 5)))
length(data$School.enrollment..primary..female....gross.)
